{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "0     0            7.0              0.27         0.36            20.7   \n",
       "1     0            6.3              0.30         0.34             1.6   \n",
       "2     0            8.1              0.28         0.40             6.9   \n",
       "3     0            7.2              0.23         0.32             8.5   \n",
       "4     0            7.2              0.23         0.32             8.5   \n",
       "\n",
       "   chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  \\\n",
       "0      0.045                 45.0                 170.0   1.0010  3.00   \n",
       "1      0.049                 14.0                 132.0   0.9940  3.30   \n",
       "2      0.050                 30.0                  97.0   0.9951  3.26   \n",
       "3      0.058                 47.0                 186.0   0.9956  3.19   \n",
       "4      0.058                 47.0                 186.0   0.9956  3.19   \n",
       "\n",
       "   sulphates  alcohol  quality  \n",
       "0       0.45      8.8        6  \n",
       "1       0.49      9.5        6  \n",
       "2       0.44     10.1        6  \n",
       "3       0.40      9.9        6  \n",
       "4       0.40      9.9        6  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/classification_sprint/winequality.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(df):\n",
    "    \"\"\"\n",
    "    Preprocesses the dataset by handling missing values, \n",
    "    converting quality labels to binary, standardizing features, \n",
    "    and splitting the data into training and testing sets.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The input dataset.\n",
    "\n",
    "    Returns:\n",
    "    tuple: ((X_train, y_train), (X_test, y_test)) - Processed training and testing sets.\n",
    "    \"\"\"\n",
    "\n",
    "    # Fill NaN values with zeros\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    # Convert wine quality to binary labels\n",
    "    df['quality'] = df['quality'].apply(lambda x: 0 if x <= 4 else 1)\n",
    "    \n",
    "    # Split the data into features and labels\n",
    "    X = df.drop('quality', axis=1)\n",
    "    y = df['quality']\n",
    "\n",
    "    # Standardize the features\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split the data into 75% training and 25% testing sets\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=42)\n",
    "\n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = data_preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.57136659  0.07127869 -0.48054096  1.17914161 -0.09303318 -0.79974133\n",
      "   0.0830898  -0.15472329 -0.36573452  0.13010447  0.06101473  0.25842195]\n",
      " [-0.57136659  1.50396711 -0.72301571  0.56008035 -0.63948302 -0.05776881\n",
      "  -0.70572997  0.62379657  0.16787589 -0.86828773 -0.47467813 -0.99931317]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_SVC_model(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Trains a Support Vector Classifier (SVC) model on the given training data.\n",
    "\n",
    "    Parameters:\n",
    "    X_train (array-like): The training features.\n",
    "    y_train (array-like): The training labels.\n",
    "\n",
    "    Returns:\n",
    "    SVC: The trained SVC model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Instantiate the SVC model with a fixed random state\n",
    "    model = SVC(random_state=40, gamma='auto')\n",
    "\n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = train_SVC_model(X_train,y_train)\n",
    "svc.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_scoring_function(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes the log loss for the given true and predicted values.\n",
    "\n",
    "    Parameters:\n",
    "    y_true (array-like): The true labels.\n",
    "    y_pred (array-like): The predicted probabilities.\n",
    "\n",
    "    Returns:\n",
    "    float: The log loss value rounded to 7 decimal places.\n",
    "    \"\"\"\n",
    "\n",
    "    epsilon = 1e-15\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)  # Ensure predictions are within valid range\n",
    "\n",
    "    # Compute log loss\n",
    "    N = len(y_true)\n",
    "    log_loss = - (1 / N) * np.sum(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "    return np.round(log_loss, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss value:  1.2540518\n",
      "Accuracy:  0.9637\n"
     ]
    }
   ],
   "source": [
    "# Calculates log loss and accuracy\n",
    "\n",
    "y_pred = svc.predict(X_test)\n",
    "print('Log Loss value: ', custom_scoring_function(y_test, y_pred))\n",
    "print('Accuracy: ',round(accuracy_score(y_test,y_pred),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_hyperparams(model):\n",
    "    \"\"\"\n",
    "    Retrieves the hyperparameter names of a given model.\n",
    "\n",
    "    Parameters:\n",
    "    model (object): A trained machine learning model.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of hyperparameter names.\n",
    "    \"\"\"\n",
    "    return list(model.get_params().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C',\n",
       " 'break_ties',\n",
       " 'cache_size',\n",
       " 'class_weight',\n",
       " 'coef0',\n",
       " 'decision_function_shape',\n",
       " 'degree',\n",
       " 'gamma',\n",
       " 'kernel',\n",
       " 'max_iter',\n",
       " 'probability',\n",
       " 'random_state',\n",
       " 'shrinking',\n",
       " 'tol',\n",
       " 'verbose']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get hyperparamters\n",
    "get_model_hyperparams(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter search\n",
    "\n",
    "def tune_SVC_model(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Performs hyperparameter tuning for a Support Vector Classifier (SVC) using GridSearchCV.\n",
    "\n",
    "    Parameters:\n",
    "    X_train (array-like): The training features.\n",
    "    y_train (array-like): The training labels.\n",
    "\n",
    "    Returns:\n",
    "    GridSearchCV: The fitted GridSearchCV object containing the best hyperparameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the parameter grid\n",
    "    D = {'C': [0.1, 1, 10], 'gamma': [0.01, 0.1, 1]}\n",
    "    \n",
    "    # Create the custom scorer\n",
    "    from sklearn.metrics import make_scorer\n",
    "    scorer = make_scorer(custom_scoring_function, greater_is_better=False)\n",
    "\n",
    "    # Perform grid search with 5-fold cross-validation\n",
    "    grid_search = GridSearchCV(estimator=SVC(), param_grid=D, scoring=scorer, cv=5)\n",
    "    \n",
    "    # Fit the grid search to the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    return grid_search\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss value:  1.2115421\n",
      "Accuracy:  0.9649\n"
     ]
    }
   ],
   "source": [
    "# Tune the SVC model using GridSearchCV to find the best hyperparameters\n",
    "\n",
    "svc_tuned = tune_SVC_model(X_train, y_train)\n",
    "y_pred = svc_tuned.predict(X_test)\n",
    "print('Log Loss value: ',custom_scoring_function(y_test,y_pred))\n",
    "print('Accuracy: ',round(accuracy_score(y_test,y_pred),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal model parameters\n",
    "\n",
    "def get_best_params(grid_search):\n",
    "    \"\"\"\n",
    "    Retrieves the best hyperparameters from a trained GridSearchCV object.\n",
    "\n",
    "    Parameters:\n",
    "    grid_search (GridSearchCV): The fitted GridSearchCV object.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing the optimal hyperparameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the best hyperparameters from the GridSearchCV object\n",
    "    best_params = grid_search.best_params_\n",
    "    \n",
    "    # Return the dictionary of optimal parameters\n",
    "    return best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The best parameter for the model \n",
    "\n",
    "get_best_params(svc_tuned)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
